version: '2.3'
services:
  vl-interpret:
    shm_size: '1024m'
    build:
      context: .
      dockerfile: Dockerfile
    image: vl-interpret
    tty: true
    volumes:
      - .:/vl-interpret
    ports:
      - 6006:6006
    environment:
      - PASSWORD=none
    working_dir: /vl-interpret

  clip-api:
    shm_size: '1024m'
    build: https://github.com/multitel-ai/berlin_workshop_xai.git#main
    image: clip-api
    tty: true
    ports:
      - 5000:5000
    environment:
      - PASSWORD=none
      - NVIDIA_VISIBLE_DEVICES=all
    runtime: nvidia
   